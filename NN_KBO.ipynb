{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1 = open('KBOtest1_train.txt', 'rb')\n",
    "f2 = open('KBOtest1_label.txt', 'rb')\n",
    "\n",
    "train = pickle.load(f1)\n",
    "train = train[0:-100]\n",
    "trainlabel = pickle.load(f2)\n",
    "trainlabel = trainlabel[0:-99]\n",
    "test = train[-30:-1]\n",
    "testlabel = trainlabel[-30:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VanillaNN:\n",
    "    def __init__(self):\n",
    "        self.epoch_list                  = []\n",
    "        self.train_error_value_list      = []\n",
    "        self.test_error_value_list       = []\n",
    "        self.test_accuracy_list          = []\n",
    "            \n",
    "    def setData(self, n_input, n_classes, trainData, trainlabelData, testData, testlabelData):\n",
    "        self.n_input     = n_input            \n",
    "        self.n_classes   = n_classes          \n",
    "        self.trainData   = trainData\n",
    "        self.trainlabelData   = trainlabelData\n",
    "        self.testData    = testData\n",
    "        self.testlabelData = testlabelData\n",
    "\n",
    "    #Create model\n",
    "    def makeModel(self, n_hidden, learning_rate):\n",
    "        self.n_hidden        = n_hidden\n",
    "        self.numHiddenLayer  = len(n_hidden)\n",
    "        self.learning_rate   = learning_rate\n",
    "        \n",
    "        #tf Graph input\n",
    "        self.x = tf.placeholder(tf.float32, (None, self.n_input))\n",
    "        self.y = tf.placeholder(tf.float32, (None, self.n_classes))\n",
    "\n",
    "        if (self.numHiddenLayer == 0):\n",
    "            self.weight = tf.Variable(tf.zeros([self.n_input, self.n_classes]))\n",
    "            self.bias = tf.Variable(tf.zeros([self.n_classes]))\n",
    "            self.pred = tf.add(tf.matmul(self.x, self.weight), self.bias)\n",
    "        else:\n",
    "            #Store layers weight & bias\n",
    "            self.weights = {\n",
    "                1: tf.Variable(tf.random_normal([self.n_input, self.n_hidden[0]])),\n",
    "                'out': tf.Variable(tf.random_normal([self.n_hidden[0], self.n_classes]))\n",
    "            }\n",
    "            self.biases = {\n",
    "                1: tf.Variable(tf.random_normal([self.n_hidden[0]])),\n",
    "                'out': tf.Variable(tf.random_normal([self.n_classes]))\n",
    "            }\n",
    "            \n",
    "            self.u = tf.add(tf.matmul(self.x, self.weights[1]), self.biases[1])\n",
    "            self.z = tf.nn.relu(self.u)\n",
    "\n",
    "            if (self.numHiddenLayer >= 2):\n",
    "                for i in range(self.numHiddenLayer - 1):\n",
    "                    self.weights[i+2] = tf.Variable(tf.random_normal([self.n_hidden[i], self.n_hidden[i+1]]))\n",
    "                    self.biases[i+2] = tf.Variable(tf.random_normal([self.n_hidden[i+1]]))\n",
    "                self.weights['out'] = tf.Variable(tf.random_normal([self.n_hidden[self.numHiddenLayer - 1], self.n_classes]))\n",
    "                self.biases['out'] = tf.Variable(tf.random_normal([self.n_classes]))\n",
    "        \n",
    "                for i in range(self.numHiddenLayer - 1):\n",
    "                    self.u = tf.add(tf.matmul(self.z, self.weights[i+2]), self.biases[i+2])\n",
    "                    self.z = tf.nn.relu(self.u)\n",
    "        \n",
    "            self.pred = tf.add(tf.matmul(self.z, self.weights['out']), self.biases['out'])\n",
    "        \n",
    "        self.error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.pred, self.y))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.error)\n",
    "\n",
    "        self.prediction_ground_truth = tf.equal(tf.argmax(self.pred, 1), tf.argmax(self.y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.prediction_ground_truth, tf.float32))\n",
    "    \n",
    "    def learning(self, batch_size, training_epochs):\n",
    "        self.batch_size      = batch_size\n",
    "        self.training_epochs = training_epochs\n",
    "        self.init = tf.global_variables_initializer()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            self.total_batch = int(math.ceil(len(self.trainData)/float(self.batch_size)))\n",
    "            print \"Total batch: %d\" % self.total_batch\n",
    "\n",
    "            for epoch in range(self.training_epochs):\n",
    "                for i in range(self.total_batch):\n",
    "                    batch_images = self.trainData[0+i*self.total_batch:self.total_batch+i*self.total_batch]\n",
    "                    batch_labels = self.trainlabelData[0+i*self.total_batch:self.total_batch+i*self.total_batch]\n",
    "                    _, error_value = sess.run((self.optimizer, self.error), \n",
    "                                              feed_dict={self.x: batch_images, self.y: batch_labels})\n",
    "\n",
    "                self.epoch_list.append(epoch)\n",
    "                \n",
    "                self.train_error_value_list.append(error_value)\n",
    "                \n",
    "                self.printLossAccuracyForTestData(epoch, sess)\n",
    "                \n",
    "            self.drawFalsePrediction(sess, 10)\n",
    "\n",
    "            print(\"Training % Test finished!\")\n",
    "            \n",
    "    def printLossAccuracyForTestData(self, epoch, sess):\n",
    "        accuracy_value, error_value = sess.run((self.accuracy, self.error), \n",
    "                                               feed_dict={self.x: self.testData, self.y: self.testlabelData})\n",
    "        self.test_error_value_list.append(error_value)\n",
    "        self.test_accuracy_list.append(accuracy_value)\n",
    "        print \"epoch: %d, test_error_value: %f, test_accuracy: %f\" % (epoch, error_value, accuracy_value)\n",
    "        \n",
    "    def drawFalsePrediction(self, sess, numPrintImages):\n",
    "        ground_truth = sess.run(tf.argmax(self.y, 1), feed_dict={self.y: self.testlabelData})\n",
    "        prediction = sess.run(tf.argmax(self.pred, 1), feed_dict={self.x: self.testData})\n",
    "\n",
    "        j = 1\n",
    "        for i in range(len(self.testData)):\n",
    "            if (j > numPrintImages):\n",
    "                break;\n",
    "            if (prediction[i] != ground_truth[i]):\n",
    "                print \"Error Index: %s, Prediction: %s, Ground Truth: %s\" % (i, prediction[i], ground_truth[i])\n",
    "                j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla (Sigle Layer + Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parameter: Batch_size, Training_epochs, learning_rate, n_hidden\n",
    "vanilla = VanillaNN()\n",
    "vanilla.setData(n_input = 30, \n",
    "                n_classes = 3, \n",
    "                trainData = train, \n",
    "                trainlabelData = trainlabel,\n",
    "                testData = test,\n",
    "                testlabelData = testlabel)\n",
    "vanilla.makeModel(n_hidden = [], learning_rate = 0.001)\n",
    "vanilla.learning(batch_size = 100, training_epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla (Multi Layer + Batch) - 2 Hidden Layers, 128 neurons per Hidden Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vanilla2 = VanillaNN()\n",
    "vanilla2.setData(n_input = 30,\n",
    "                      n_classes = 3,\n",
    "                      trainData = train, \n",
    "                    trainlabelData = trainlabel,\n",
    "                    testData = test,\n",
    "                    testlabelData = testlabel)\n",
    "vanilla2.makeModel(n_hidden = [128, 128], learning_rate = 0.001)\n",
    "vanilla2.learning(batch_size = 100, training_epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla (Multi Layer + Batch) - 3 Hidden Layers, 256 neurons per Hidden Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parameter: Batch_size, Training_epochs, learning_rate, n_hidden\n",
    "vanilla3 = VanillaNN()\n",
    "vanilla3.setData(n_input = 30,\n",
    "                      n_classes = 3,\n",
    "                      trainData = train, \n",
    "                    trainlabelData = trainlabel,\n",
    "                    testData = test,\n",
    "                    testlabelData = testlabel)\n",
    "vanilla3.makeModel(n_hidden = [256, 256, 256], learning_rate = 0.001)\n",
    "vanilla3.learning(batch_size = 100, training_epochs = 50)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
